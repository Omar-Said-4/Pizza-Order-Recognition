{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Masking, Bidirectional, Multiply, Lambda\n",
    "from tensorflow.keras import Model, Input\n",
    "import gensim as gs\n",
    "from tensorflow.keras.models import Model\n",
    "import ast\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #! check if tensorflow is using GPU\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# print(tf.__version__)\n",
    "# if gpus:\n",
    "#     print(f\"TensorFlow is using {len(gpus)} GPU(s).\")\n",
    "#     for gpu in gpus:\n",
    "#         print(f\"GPU: {gpu.name}\")\n",
    "# else:\n",
    "#     print(\"TensorFlow is not using any GPUs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_labels(data_path, labels_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = [ast.literal_eval(line.strip()) for line in f]\n",
    "    with open(labels_path, 'r') as f:\n",
    "        labels = [ast.literal_eval(line.strip()) for line in f]\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000\n",
      "51000\n",
      "[['i', 'like', 'one', 'pizza', 'with', 'red', 'onion', 'fry', 'onion', 'and', 'mozarella', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'anchovy', 'caramelize', 'red', 'onion', 'and', 'roast', 'green', 'pepper', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'applewood', 'bacon', 'grill', 'pineapple', 'and', 'shrimp', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'pesto', 'sauce', 'roast', 'pepper', 'and', 'peppperonis', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'peperronni', 'spicy', 'red', 'sauce', 'and', 'mushroom', 'without', 'thin', 'crust']]\n",
      "[[0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7]]\n",
      "51000\n",
      "[[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# data, labels = load_data_labels('training_data_processed.txt', 'train_order_category_labels.txt')\n",
    "data, labels = load_data_labels('train_data_order_details.txt', 'train_labels_order_details.txt')\n",
    "_,Xmodel1=load_data_labels('trian_data_order_category.txt','train_labels_order_category.txt')\n",
    "# data2, labels2 = load_data_labels('synthetic_orders.txt', 'synthetic_labels.txt')\n",
    "# data.extend(data2)\n",
    "# labels.extend(labels2)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "print(data[:5])\n",
    "print(labels[:5])\n",
    "print(len(Xmodel1))\n",
    "print(Xmodel1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n",
      "[[2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 2, 2, 0, 0, 0, 0, 0, 0], [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# dev_data, dev_labels = load_data_labels('dev_data_processed.txt', 'dev_order_category_labels.txt')\n",
    "dev_data, dev_labels = load_data_labels('dev_data_order_details.txt', 'dev_labels_order_details.txt')\n",
    "_,devXmodel1=load_data_labels('dev_data_order_category.txt','dev_labels_order_category.txt')\n",
    "print(len(devXmodel1))\n",
    "print(devXmodel1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = gs.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'like', 'one', 'pizza', 'with', 'red', 'onion', 'fry', 'onion', 'unk', 'mozarella', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'anchovy', 'caramelize', 'red', 'onion', 'unk', 'roast', 'green', 'pepper', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'applewood', 'bacon', 'grill', 'pineapple', 'unk', 'shrimp', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'pesto', 'sauce', 'roast', 'pepper', 'unk', 'unk', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'unk', 'spicy', 'red', 'sauce', 'unk', 'mushroom', 'without', 'thin', 'crust']]\n"
     ]
    }
   ],
   "source": [
    "#! get v Aand replace unknown words with unk token\n",
    "def process_sentence(sentence, model):\n",
    "    for i, word in enumerate(sentence):\n",
    "        if word not in model:\n",
    "            sentence[i] = 'unk'\n",
    "    return sentence\n",
    "\n",
    "data = [process_sentence(sentence, pretrained_model) for sentence in data]\n",
    "print(data[:5])\n",
    "vocab=set()\n",
    "for sentence in data:\n",
    "    vocab.update(sentence)\n",
    "#! get word index for each word in vocab\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=300\n",
    "input_dim=len(vocab)\n",
    "output_dim=11\n",
    "max_length=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in dev_data:\n",
    "    for i,word in enumerate(tokens):\n",
    "        if word not in vocab:\n",
    "            tokens[i] = 'unk'\n",
    "X_d=[[word2idx[word] for word in sentence] for sentence in dev_data]\n",
    "X_d=pad_sequences(X_d, maxlen=max_length, padding='post', value=-1)\n",
    "X_categories_d = [[category for category in sentence_categories] for sentence_categories in devXmodel1]\n",
    "X_categories_d = pad_sequences(X_categories_d, maxlen=max_length, padding='post', value=2)  # Default to \"NEITHER\" = 2\n",
    "Y_d=pad_sequences(dev_labels, maxlen=max_length, padding='post', value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! get embeddings matrix\n",
    "def get_embeddings_matrix(model, vocab):\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_dim = model.vector_size\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for i, word in enumerate(vocab):\n",
    "        if word in model:\n",
    "            embedding_matrix[i] = model[word]\n",
    "    return embedding_matrix\n",
    "embedding_matrix = get_embeddings_matrix(pretrained_model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! replace words with their index in vocab and pad sentences\n",
    "X=[[word2idx[word] for word in sentence] for sentence in data]\n",
    "X=pad_sequences(X, maxlen=max_length, padding='post', value=-1)\n",
    "X_categories = [[category for category in sentence_categories] for sentence_categories in Xmodel1]\n",
    "X_categories = pad_sequences(X_categories, maxlen=max_length, padding='post', value=2)  # Default to \"NEITHER\" = 2\n",
    "Y=pad_sequences(labels, maxlen=max_length, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_seq = Input(shape=(None,), dtype=tf.int32)\n",
    "# masked_input = Masking(mask_value=-1)(input_seq)\n",
    "\n",
    "# embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim, weights=[embedding_matrix], trainable=True, mask_zero=False)(masked_input)\n",
    "\n",
    "# lstm_output = Bidirectional(LSTM(32, return_sequences=True))(embedding)\n",
    "\n",
    "# query = LSTM(32, return_sequences=True)(lstm_output)  \n",
    "# key = LSTM(32, return_sequences=True)(lstm_output)    \n",
    "# value = LSTM(32, return_sequences=True)(lstm_output)  \n",
    "\n",
    "# attention_output = Attention(use_scale=True, causal=False)([query, key, value])\n",
    "\n",
    "# dropout_output = Dropout(0.8)(attention_output)\n",
    "# output = Dense(output_dim, activation='softmax')(dropout_output)\n",
    "\n",
    "# model = Model(inputs=input_seq, outputs=output)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss',\n",
    "#     factor=0.5,\n",
    "#     patience=5,\n",
    "#     min_lr=1e-9,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X, \n",
    "#     Y, \n",
    "#     validation_data=(X_d, Y_d),  # Add validation data\n",
    "#     callbacks=[lr_scheduler], \n",
    "#     epochs=25,\n",
    "#     batch_size=1024\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 14s 54ms/step - loss: 2.2165 - accuracy: 0.9769 - val_loss: 2.1804 - val_accuracy: 0.9978 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1397 - accuracy: 0.9990 - val_loss: 2.1737 - val_accuracy: 0.9987 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 2.1365 - accuracy: 0.9996 - val_loss: 2.1724 - val_accuracy: 0.9990 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1356 - accuracy: 0.9998 - val_loss: 2.1716 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 2.1352 - accuracy: 0.9999 - val_loss: 2.1711 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 2.1350 - accuracy: 0.9999 - val_loss: 2.1709 - val_accuracy: 0.9995 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 2.1349 - accuracy: 1.0000 - val_loss: 2.1706 - val_accuracy: 0.9996 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 2.1348 - accuracy: 1.0000 - val_loss: 2.1704 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 2.1348 - accuracy: 1.0000 - val_loss: 2.1704 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1704 - val_accuracy: 0.9996 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1704 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 5s 48ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 21/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.1346 - accuracy: 1.0000\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 5.0000e-04\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 5s 46ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9998 - lr: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c5313ad90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define category mask function\n",
    "def create_category_mask(categories):\n",
    "    # Updated mask for 11 output dimensions (aligned with the output_dim)\n",
    "    category_to_mask = tf.constant([\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],  # PIZZA\n",
    "        [1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1],  # DRINK\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   # NEITHER\n",
    "    ], dtype=tf.float32)  # Shape: (3, 11) for output_dim of 11\n",
    "\n",
    "    # Replace padding (-1) with NEITHER (category index 2)\n",
    "    categories = tf.where(categories == -1, 2, categories)\n",
    "\n",
    "    # Create the mask: gather the appropriate row based on the category index\n",
    "    mask = tf.gather(category_to_mask, categories)  # Shape: (batch_size, max_length, 11)\n",
    "    return mask\n",
    "\n",
    "# Define token input and category input\n",
    "input_tokens = Input(shape=(max_length,), dtype='int32', name='tokens')  # Token indices\n",
    "input_categories = Input(shape=(max_length,), dtype='int32', name='categories')  # Category predictions\n",
    "\n",
    "# Embedding layer for tokens (with a pre-trained embedding matrix)\n",
    "x = Masking(mask_value=-1)(input_tokens)  # Mask the padding (-1)\n",
    "x = Embedding(input_dim=len(vocab), output_dim=embedding_dim, \n",
    "              weights=[embedding_matrix], trainable=True)(x)\n",
    "\n",
    "# Embedding layer for categories (fixed size of 3 categories: PIZZA, DRINK, NEITHER)\n",
    "category_embedding = Embedding(input_dim=3, output_dim=8, trainable=True)(input_categories)\n",
    "\n",
    "# Concatenate token embeddings and category embeddings\n",
    "x = tf.concat([x, category_embedding], axis=-1)  # Concatenate along the last dimension\n",
    "\n",
    "# BiLSTM and Dropout layer\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)  # BiLSTM to capture sequential dependencies\n",
    "x = Dropout(0.6)(x)  # Dropout to avoid overfitting\n",
    "\n",
    "# Dense layer for logits (predictions) without softmax yet\n",
    "logits = Dense(output_dim, activation=None)(x)  # Output shape: (batch_size, max_length, 11)\n",
    "\n",
    "# Apply category-specific masking (to set certain logits to zero based on category)\n",
    "mask = Lambda(create_category_mask)(input_categories)  # Apply the category mask\n",
    "masked_logits = Multiply()([logits, mask])  # Element-wise multiplication of logits and mask\n",
    "\n",
    "# Final softmax activation for probabilities\n",
    "output = tf.keras.activations.softmax(masked_logits, axis=-1)  # Apply softmax across the last dimension\n",
    "\n",
    "# Build and compile the model\n",
    "model = Model(inputs=[input_tokens, input_categories], outputs=output)\n",
    "\n",
    "# Compile the model with Adam optimizer, sparse categorical crossentropy loss, and accuracy as a metric\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # The metric to monitor (you can use 'accuracy' or another metric)\n",
    "    factor=0.5,              # Factor by which the learning rate will be reduced\n",
    "    patience=5,              # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-9,             # Minimum value for the learning rate\n",
    "    verbose=1                # Print a message when the learning rate is reduced\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [X, X_categories],  # Token sequences (X) and category predictions (X_categories)\n",
    "    Y,                  # Labels for token classification (Y)\n",
    "    validation_data=([X_d, X_categories_d], Y_d),  # Validation data\n",
    "    epochs=25,  # Number of epochs\n",
    "    batch_size=512,  # Batch size\n",
    "    callbacks=[lr_scheduler]  # Learning rate scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X was index of token in embedding matrix\n",
    "# # X -> \n",
    "\n",
    "# model.fit(\n",
    "#     X, \n",
    "#     Y, \n",
    "#     validation_data=(X_d, Y_d),  # Add validation data\n",
    "#     callbacks=[lr_scheduler], \n",
    "#     epochs=25,\n",
    "#     batch_size=512\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " tokens (InputLayer)            [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, 100)          0           ['tokens[0][0]']                 \n",
      "                                                                                                  \n",
      " categories (InputLayer)        [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 300)     112800      ['masking[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 100, 8)       24          ['categories[0][0]']             \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 100, 308)     0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 100, 128)     190976      ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100, 128)     0           ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100, 11)      1419        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 100, 11)      0           ['categories[0][0]']             \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 100, 11)      0           ['dense[0][0]',                  \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (None, 100, 11)      0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 305,219\n",
      "Trainable params: 305,219\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 21s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your token data in X and category data in X_categories\n",
    "preds_train = model.predict([X, X_categories])  # Pass both inputs as a list\n",
    "preds_train = np.argmax(preds_train, axis=-1)  # Get the class with the highest probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9994313725490196\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(X)):\n",
    "    mask=X[i]!=-1\n",
    "    if np.all(preds_train[i][mask]==Y[i][mask]):\n",
    "        count+=1\n",
    "print(f\"Accuracy on training data: {count/len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on the development set\n",
    "# preds_dev = Bidirectional_LSTM_model.predict(X)\n",
    "# preds_dev = np.argmax(preds_dev, axis=-1)\n",
    "\n",
    "# count = 0  # Count of completely correct sequences\n",
    "# last_index_error_count = 0  # Count of sequences with only last index error\n",
    "\n",
    "# for i in range(len(data)):\n",
    "#     # Get original sequence lengths before padding\n",
    "#     original_length = len(data[i])\n",
    "    \n",
    "#     # Extract predictions and true labels for the original sequence\n",
    "#     pred_seq = preds_dev[i][:original_length]\n",
    "#     true_seq = labels[i]  # Original labels are unpadded\n",
    "    \n",
    "#     # Check if the sequence is entirely correct\n",
    "#     if (pred_seq == true_seq).all():\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         # Check if only the last index is incorrect\n",
    "#         if (pred_seq[:-1] == true_seq[:-1]).all() and (pred_seq[-1] != true_seq[-1]):\n",
    "#             last_index_error_count += 1\n",
    "        \n",
    "#         # Print debug information for mismatches\n",
    "#         print(f\"Index with mismatch: {i}\")\n",
    "#         print(f\"Predicted: {pred_seq}\")\n",
    "#         print(f\"True:      {true_seq}\")\n",
    "#         print(\"--------------------------------------------\")\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Sequences with only last index error: {last_index_error_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data, dev_labels = load_data_labels('dev_data_processed.txt', 'dev_order_category_labels.txt')\n",
    "# for tokens in dev_data:\n",
    "#     for i,word in enumerate(tokens):\n",
    "#         if word not in vocab!= 'a':\n",
    "#             tokens[i] = 'unk'\n",
    "# X_d=[[word2idx[word] for word in sentence] for sentence in dev_data]\n",
    "# X_d=pad_sequences(X_d, maxlen=max_length, padding='post', value=-1)\n",
    "# Y_d=pad_sequences(dev_labels, maxlen=max_length, padding='post', value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 15ms/step\n",
      "Index with mismatch: 163\n",
      "Predicted: [0 0 0 0 1 8 8 8 1 8 8 0 1 8 8 0 2 2]\n",
      "True:      [0, 0, 0, 0, 1, 8, 8, 0, 1, 8, 0, 0, 1, 8, 0, 0, 2, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 180\n",
      "Predicted: [0 0 1 2 2 0]\n",
      "True:      [0, 0, 1, 2, 0, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 218\n",
      "Predicted: [0 0 1 2 1 0 0 0 4 0 4]\n",
      "True:      [0, 0, 1, 2, 0, 0, 0, 0, 4, 0, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 224\n",
      "Predicted: [0 0 1 2 0 0 0 0 4 0 4 0 0 0 0 0 0 0 0 7 3]\n",
      "True:      [0, 0, 1, 2, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 228\n",
      "Predicted: [0 0 0 1 3 3 0 0 5 4]\n",
      "True:      [0, 0, 0, 1, 0, 3, 0, 0, 5, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 230\n",
      "Predicted: [0 0 0 0 0 1 2 3 3 0 0 4 4 0 0 4 0 1 4 0 4 4 0 1 2 8]\n",
      "True:      [0, 0, 0, 0, 0, 1, 2, 3, 3, 0, 0, 4, 4, 0, 0, 4, 0, 5, 5, 5, 4, 4, 0, 1, 2, 8]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 231\n",
      "Predicted: [0 0 1 2 0 0 4 4 0 4 0 0 0 5 4]\n",
      "True:      [0, 0, 1, 2, 0, 0, 4, 4, 0, 0, 0, 0, 0, 5, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 242\n",
      "Predicted: [0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 3 3 0 0 0 4 0 4 0]\n",
      "True:      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 246\n",
      "Predicted: [0 0 1 2 2 0 0 4 0 4 0 0 5 4]\n",
      "True:      [0, 0, 1, 2, 0, 0, 0, 4, 0, 4, 0, 0, 5, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 309\n",
      "Predicted: [0 0 0 1 2 0 0 4 4 0 4]\n",
      "True:      [0, 0, 0, 1, 2, 0, 0, 0, 4, 0, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 321\n",
      "Predicted: [0 0 1 4 0 4 0 0 0 7 7]\n",
      "True:      [0, 0, 1, 4, 0, 4, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 329\n",
      "Predicted: [ 0  0  1  8  1 10  8  8  0  1  8  0  0]\n",
      "True:      [0, 0, 1, 8, 1, 2, 8, 8, 0, 1, 8, 0, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 781\n",
      "Predicted: [0 0 0 0 1 2 0 0 4 0 4 0 0 0 0 0 0 0 0 4]\n",
      "True:      [0, 0, 0, 0, 1, 2, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 6]\n",
      "--------------------------------------------\n",
      "Accuracy on dev_data: 0.9847\n",
      "Sequences with only last index error: 2\n"
     ]
    }
   ],
   "source": [
    "# Predict on the development set\n",
    "preds_dev = model.predict([X_d,X_categories_d])\n",
    "preds_dev = np.argmax(preds_dev, axis=-1)\n",
    "\n",
    "count = 0  # Count of completely correct sequences\n",
    "last_index_error_count = 0  # Count of sequences with only last index error\n",
    "\n",
    "for i in range(len(dev_data)):\n",
    "    # Get original sequence lengths before padding\n",
    "    original_length = len(dev_data[i])\n",
    "    \n",
    "    # Extract predictions and true dev_labels for the original sequence\n",
    "    pred_seq = preds_dev[i][:original_length]\n",
    "    true_seq = dev_labels[i]  # Original dev_labels are unpadded\n",
    "    \n",
    "    # Check if the sequence is entirely correct\n",
    "    if (pred_seq == true_seq).all():\n",
    "        count += 1\n",
    "    else:\n",
    "        # Check if only the last index is incorrect\n",
    "        if (pred_seq[:-1] == true_seq[:-1]).all() and (pred_seq[-1] != true_seq[-1]):\n",
    "            last_index_error_count += 1\n",
    "        \n",
    "        # Print debug information for mismatches\n",
    "        print(f\"Index with mismatch: {i}\")\n",
    "        \n",
    "        print(f\"Predicted: {pred_seq}\")\n",
    "        print(f\"True:      {true_seq}\")\n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy on dev_data: {count / len(dev_data):.4f}\")\n",
    "print(f\"Sequences with only last index error: {last_index_error_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in HDF5 format\n",
    "# model.save(\"order_details_model.h5\")\n",
    "# model= tf.keras.models.load_model(\"order_details_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['want', 'one', 'pizza', 'with', 'pepproni', 'and', 'large', 'size', 'pepproni', 'pizza']]\n",
      "[[2, 0, 0, 0, 0, 2, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "test_data,test_labels_order_category=load_data_labels('test_data_order_details.txt','test_labels_order_category.txt')\n",
    "print(test_data)\n",
    "print(test_labels_order_category)\n",
    "for tokens in test_data:\n",
    "    for i,word in enumerate(tokens):\n",
    "        if word not in vocab:\n",
    "            tokens[i] = 'unk'\n",
    "X_test=[[word2idx[word] for word in sentence] for sentence in test_data]\n",
    "X_test=pad_sequences(X_test, maxlen=max_length, padding='post', value=-1)\n",
    "X_categories_test = [[category for category in sentence_categories] for sentence_categories in test_labels_order_category]\n",
    "X_categories_test = pad_sequences(X_categories_test, maxlen=max_length, padding='post', value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[0 1 0 0 4 0 2 2 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict([X_test, X_categories_test])  # Pass both inputs as a list\n",
    "pred_test = np.argmax(pred_test, axis=-1)  # Get the class with the highest probability\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post processing to get the order details in exr format\n",
    "for i in range(len(test_data)):\n",
    "    # Get original sequence lengths before padding\n",
    "    original_length = len(test_data[i])\n",
    "    \n",
    "    # Extract predictions and true dev_labels for the original sequence\n",
    "    pred_test_seq = pred_test[i][:original_length]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
