{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\anaconda3\\envs\\nlp\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Masking, Bidirectional, Multiply, Lambda\n",
    "from tensorflow.keras import Model, Input\n",
    "import gensim as gs\n",
    "from tensorflow.keras.models import Model\n",
    "import ast\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using 1 GPU(s).\n",
      "GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#! check if tensorflow is using GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f\"TensorFlow is using {len(gpus)} GPU(s).\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU: {gpu.name}\")\n",
    "else:\n",
    "    print(\"TensorFlow is not using any GPUs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_labels(data_path, labels_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        data = [ast.literal_eval(line.strip()) for line in f]\n",
    "    with open(labels_path, 'r') as f:\n",
    "        labels = [ast.literal_eval(line.strip()) for line in f]\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000\n",
      "51000\n",
      "[['i', 'like', 'one', 'pizza', 'with', 'red', 'onion', 'fry', 'onion', 'and', 'mozarella', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'anchovy', 'caramelize', 'red', 'onion', 'and', 'roast', 'green', 'pepper', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'applewood', 'bacon', 'grill', 'pineapple', 'and', 'shrimp', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'pesto', 'sauce', 'roast', 'pepper', 'and', 'peppperonis', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'peperronni', 'spicy', 'red', 'sauce', 'and', 'mushroom', 'without', 'thin', 'crust']]\n",
      "[[0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7], [0, 0, 1, 0, 0, 4, 4, 4, 4, 0, 4, 0, 7, 7]]\n",
      "51000\n",
      "[[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# data, labels = load_data_labels('training_data_processed.txt', 'train_order_category_labels.txt')\n",
    "data, labels = load_data_labels('train_data_order_details.txt', 'train_labels_order_details.txt')\n",
    "_,Xmodel1=load_data_labels('trian_data_order_category.txt','train_labels_order_category.txt')\n",
    "# data2, labels2 = load_data_labels('synthetic_orders.txt', 'synthetic_labels.txt')\n",
    "# data.extend(data2)\n",
    "# labels.extend(labels2)\n",
    "print(len(data))\n",
    "print(len(labels))\n",
    "print(data[:5])\n",
    "print(labels[:5])\n",
    "print(len(Xmodel1))\n",
    "print(Xmodel1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847\n",
      "[[2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0], [2, 2, 2, 2, 0, 0, 0, 0, 0, 0], [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# dev_data, dev_labels = load_data_labels('dev_data_processed.txt', 'dev_order_category_labels.txt')\n",
    "dev_data, dev_labels = load_data_labels('dev_data_order_details.txt', 'dev_labels_order_details.txt')\n",
    "_,devXmodel1=load_data_labels('dev_data_order_category.txt','dev_labels_order_category.txt')\n",
    "print(len(devXmodel1))\n",
    "print(devXmodel1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = gs.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'like', 'one', 'pizza', 'with', 'red', 'onion', 'fry', 'onion', 'unk', 'mozarella', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'anchovy', 'caramelize', 'red', 'onion', 'unk', 'roast', 'green', 'pepper', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'applewood', 'bacon', 'grill', 'pineapple', 'unk', 'shrimp', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'pesto', 'sauce', 'roast', 'pepper', 'unk', 'unk', 'without', 'thin', 'crust'], ['i', 'like', 'one', 'pizza', 'with', 'unk', 'spicy', 'red', 'sauce', 'unk', 'mushroom', 'without', 'thin', 'crust']]\n"
     ]
    }
   ],
   "source": [
    "#! get v Aand replace unknown words with unk token\n",
    "def process_sentence(sentence, model):\n",
    "    for i, word in enumerate(sentence):\n",
    "        if word not in model:\n",
    "            sentence[i] = 'unk'\n",
    "    return sentence\n",
    "\n",
    "data = [process_sentence(sentence, pretrained_model) for sentence in data]\n",
    "print(data[:5])\n",
    "vocab=set()\n",
    "for sentence in data:\n",
    "    vocab.update(sentence)\n",
    "#! get word index for each word in vocab\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=300\n",
    "input_dim=len(vocab)\n",
    "output_dim=11\n",
    "max_length=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in dev_data:\n",
    "    for i,word in enumerate(tokens):\n",
    "        if word not in vocab:\n",
    "            tokens[i] = 'unk'\n",
    "X_d=[[word2idx[word] for word in sentence] for sentence in dev_data]\n",
    "X_d=pad_sequences(X_d, maxlen=max_length, padding='post', value=-1)\n",
    "X_categories_d = [[category for category in sentence_categories] for sentence_categories in devXmodel1]\n",
    "X_categories_d = pad_sequences(X_categories_d, maxlen=max_length, padding='post', value=2)  # Default to \"NEITHER\" = 2\n",
    "Y_d=pad_sequences(dev_labels, maxlen=max_length, padding='post', value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! get embeddings matrix\n",
    "def get_embeddings_matrix(model, vocab):\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_dim = model.vector_size\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for i, word in enumerate(vocab):\n",
    "        if word in model:\n",
    "            embedding_matrix[i] = model[word]\n",
    "    return embedding_matrix\n",
    "embedding_matrix = get_embeddings_matrix(pretrained_model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! replace words with their index in vocab and pad sentences\n",
    "X=[[word2idx[word] for word in sentence] for sentence in data]\n",
    "X=pad_sequences(X, maxlen=max_length, padding='post', value=-1)\n",
    "X_categories = [[category for category in sentence_categories] for sentence_categories in Xmodel1]\n",
    "X_categories = pad_sequences(X_categories, maxlen=max_length, padding='post', value=2)  # Default to \"NEITHER\" = 2\n",
    "Y=pad_sequences(labels, maxlen=max_length, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_seq = Input(shape=(None,), dtype=tf.int32)\n",
    "# masked_input = Masking(mask_value=-1)(input_seq)\n",
    "\n",
    "# embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim, weights=[embedding_matrix], trainable=True, mask_zero=False)(masked_input)\n",
    "\n",
    "# lstm_output = Bidirectional(LSTM(32, return_sequences=True))(embedding)\n",
    "\n",
    "# query = LSTM(32, return_sequences=True)(lstm_output)  \n",
    "# key = LSTM(32, return_sequences=True)(lstm_output)    \n",
    "# value = LSTM(32, return_sequences=True)(lstm_output)  \n",
    "\n",
    "# attention_output = Attention(use_scale=True, causal=False)([query, key, value])\n",
    "\n",
    "# dropout_output = Dropout(0.8)(attention_output)\n",
    "# output = Dense(output_dim, activation='softmax')(dropout_output)\n",
    "\n",
    "# model = Model(inputs=input_seq, outputs=output)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss',\n",
    "#     factor=0.5,\n",
    "#     patience=5,\n",
    "#     min_lr=1e-9,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X, \n",
    "#     Y, \n",
    "#     validation_data=(X_d, Y_d),  # Add validation data\n",
    "#     callbacks=[lr_scheduler], \n",
    "#     epochs=25,\n",
    "#     batch_size=1024\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 13s 52ms/step - loss: 2.2159 - accuracy: 0.9764 - val_loss: 2.1795 - val_accuracy: 0.9980 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1396 - accuracy: 0.9990 - val_loss: 2.1741 - val_accuracy: 0.9987 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.1366 - accuracy: 0.9996 - val_loss: 2.1723 - val_accuracy: 0.9990 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.1357 - accuracy: 0.9998 - val_loss: 2.1717 - val_accuracy: 0.9992 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1353 - accuracy: 0.9999 - val_loss: 2.1711 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1351 - accuracy: 0.9999 - val_loss: 2.1708 - val_accuracy: 0.9995 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1349 - accuracy: 0.9999 - val_loss: 2.1705 - val_accuracy: 0.9995 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.1348 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.1348 - accuracy: 1.0000 - val_loss: 2.1703 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1701 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 5s 45ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.9998 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 5s 45ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.9998 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.1347 - accuracy: 1.0000 - val_loss: 2.1702 - val_accuracy: 0.9997 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1701 - val_accuracy: 0.9998 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.1346 - accuracy: 1.0000\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.9998 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1701 - val_accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 5s 45ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 2.1346 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.9998 - lr: 5.0000e-04\n",
      "Epoch 21/25\n",
      " 80/100 [=======================>......] - ETA: 0s - loss: 2.1345 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 64\u001b[0m\n\u001b[0;32m     55\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\n\u001b[0;32m     56\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,      \u001b[38;5;66;03m# The metric to monitor (you can use 'accuracy' or another metric)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,              \u001b[38;5;66;03m# Factor by which the learning rate will be reduced\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m                \u001b[38;5;66;03m# Print a message when the learning rate is reduced\u001b[39;00m\n\u001b[0;32m     61\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_categories\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Token sequences (X) and category predictions (X_categories)\u001b[39;49;00m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# Labels for token classification (Y)\u001b[39;49;00m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_categories_d\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_d\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data\u001b[39;49;00m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Learning rate scheduler\u001b[39;49;00m\n\u001b[0;32m     71\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define category mask function\n",
    "def create_category_mask(categories):\n",
    "    # Updated mask for 11 output dimensions (aligned with the output_dim)\n",
    "    category_to_mask = tf.constant([\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],  # PIZZA\n",
    "        [1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1],  # DRINK\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   # NEITHER\n",
    "    ], dtype=tf.float32)  # Shape: (3, 11) for output_dim of 11\n",
    "\n",
    "    # Replace padding (-1) with NEITHER (category index 2)\n",
    "    categories = tf.where(categories == -1, 2, categories)\n",
    "\n",
    "    # Create the mask: gather the appropriate row based on the category index\n",
    "    mask = tf.gather(category_to_mask, categories)  # Shape: (batch_size, max_length, 11)\n",
    "    return mask\n",
    "\n",
    "# Define token input and category input\n",
    "input_tokens = Input(shape=(max_length,), dtype='int32', name='tokens')  # Token indices\n",
    "input_categories = Input(shape=(max_length,), dtype='int32', name='categories')  # Category predictions\n",
    "\n",
    "# Embedding layer for tokens (with a pre-trained embedding matrix)\n",
    "x = Masking(mask_value=-1)(input_tokens)  # Mask the padding (-1)\n",
    "x = Embedding(input_dim=len(vocab), output_dim=embedding_dim, \n",
    "              weights=[embedding_matrix], trainable=True)(x)\n",
    "\n",
    "# Embedding layer for categories (fixed size of 3 categories: PIZZA, DRINK, NEITHER)\n",
    "category_embedding = Embedding(input_dim=3, output_dim=8, trainable=True)(input_categories)\n",
    "\n",
    "# Concatenate token embeddings and category embeddings\n",
    "x = tf.concat([x, category_embedding], axis=-1)  # Concatenate along the last dimension\n",
    "\n",
    "# BiLSTM and Dropout layer\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)  # BiLSTM to capture sequential dependencies\n",
    "x = Dropout(0.6)(x)  # Dropout to avoid overfitting\n",
    "\n",
    "# Dense layer for logits (predictions) without softmax yet\n",
    "logits = Dense(output_dim, activation=None)(x)  # Output shape: (batch_size, max_length, 11)\n",
    "\n",
    "# Apply category-specific masking (to set certain logits to zero based on category)\n",
    "mask = Lambda(create_category_mask)(input_categories)  # Apply the category mask\n",
    "masked_logits = Multiply()([logits, mask])  # Element-wise multiplication of logits and mask\n",
    "\n",
    "# Final softmax activation for probabilities\n",
    "output = tf.keras.activations.softmax(masked_logits, axis=-1)  # Apply softmax across the last dimension\n",
    "\n",
    "# Build and compile the model\n",
    "model = Model(inputs=[input_tokens, input_categories], outputs=output)\n",
    "\n",
    "# Compile the model with Adam optimizer, sparse categorical crossentropy loss, and accuracy as a metric\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # The metric to monitor (you can use 'accuracy' or another metric)\n",
    "    factor=0.5,              # Factor by which the learning rate will be reduced\n",
    "    patience=5,              # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-9,             # Minimum value for the learning rate\n",
    "    verbose=1                # Print a message when the learning rate is reduced\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [X, X_categories],  # Token sequences (X) and category predictions (X_categories)\n",
    "    Y,                  # Labels for token classification (Y)\n",
    "    validation_data=([X_d, X_categories_d], Y_d),  # Validation data\n",
    "    epochs=25,  # Number of epochs\n",
    "    batch_size=512,  # Batch size\n",
    "    callbacks=[lr_scheduler]  # Learning rate scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 9s 51ms/step - loss: 0.4872 - accuracy: 0.9373 - val_loss: 0.0559 - val_accuracy: 0.9879 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.0495 - accuracy: 0.9877 - val_loss: 0.0196 - val_accuracy: 0.9970 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.0115 - val_accuracy: 0.9981 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0087 - val_accuracy: 0.9984 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9986 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0062 - val_accuracy: 0.9987 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9988 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9988 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0047 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0044 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9990 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0040 - val_accuracy: 0.9992 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0037 - val_accuracy: 0.9992 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 0.9992 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9992 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0035 - val_accuracy: 0.9992 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 9.8408e-04 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 8.9777e-04 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 8.0898e-04 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 7.5501e-04 - accuracy: 0.9999 - val_loss: 0.0030 - val_accuracy: 0.9993 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 7.0586e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 6.5316e-04 - accuracy: 0.9999 - val_loss: 0.0028 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 5.9141e-04 - accuracy: 0.9999 - val_loss: 0.0027 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 5.6288e-04 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9994 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 5.1798e-04 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9994 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a08aff58e0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # X was index of token in embedding matrix\n",
    "# # X -> \n",
    "\n",
    "# model.fit(\n",
    "#     X, \n",
    "#     Y, \n",
    "#     validation_data=(X_d, Y_d),  # Add validation data\n",
    "#     callbacks=[lr_scheduler], \n",
    "#     epochs=25,\n",
    "#     batch_size=512\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_4 (Masking)         (None, 100)               0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 100, 300)          112800    \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 100, 128)         186880    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100, 11)           1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301,099\n",
      "Trainable params: 301,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/1594 [==============================] - 19s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your token data in X and category data in X_categories\n",
    "preds_train = model.predict([X, X_categories])  # Pass both inputs as a list\n",
    "preds_train = np.argmax(preds_train, axis=-1)  # Get the class with the highest probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.9994509803921569\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(X)):\n",
    "    mask=X[i]!=-1\n",
    "    if np.all(preds_train[i][mask]==Y[i][mask]):\n",
    "        count+=1\n",
    "print(f\"Accuracy on training data: {count/len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Predict on the development set\n",
    "# preds_dev = Bidirectional_LSTM_model.predict(X)\n",
    "# preds_dev = np.argmax(preds_dev, axis=-1)\n",
    "\n",
    "# count = 0  # Count of completely correct sequences\n",
    "# last_index_error_count = 0  # Count of sequences with only last index error\n",
    "\n",
    "# for i in range(len(data)):\n",
    "#     # Get original sequence lengths before padding\n",
    "#     original_length = len(data[i])\n",
    "    \n",
    "#     # Extract predictions and true labels for the original sequence\n",
    "#     pred_seq = preds_dev[i][:original_length]\n",
    "#     true_seq = labels[i]  # Original labels are unpadded\n",
    "    \n",
    "#     # Check if the sequence is entirely correct\n",
    "#     if (pred_seq == true_seq).all():\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         # Check if only the last index is incorrect\n",
    "#         if (pred_seq[:-1] == true_seq[:-1]).all() and (pred_seq[-1] != true_seq[-1]):\n",
    "#             last_index_error_count += 1\n",
    "        \n",
    "#         # Print debug information for mismatches\n",
    "#         print(f\"Index with mismatch: {i}\")\n",
    "#         print(f\"Predicted: {pred_seq}\")\n",
    "#         print(f\"True:      {true_seq}\")\n",
    "#         print(\"--------------------------------------------\")\n",
    "\n",
    "# # Print results\n",
    "# print(f\"Sequences with only last index error: {last_index_error_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# dev_data, dev_labels = load_data_labels('dev_data_processed.txt', 'dev_order_category_labels.txt')\n",
    "# for tokens in dev_data:\n",
    "#     for i,word in enumerate(tokens):\n",
    "#         if word not in vocab!= 'a':\n",
    "#             tokens[i] = 'unk'\n",
    "# X_d=[[word2idx[word] for word in sentence] for sentence in dev_data]\n",
    "# X_d=pad_sequences(X_d, maxlen=max_length, padding='post', value=-1)\n",
    "# Y_d=pad_sequences(dev_labels, maxlen=max_length, padding='post', value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 17ms/step\n",
      "Index with mismatch: 163\n",
      "Predicted: [0 0 0 0 1 8 8 8 1 8 8 0 1 8 8 8 2 2]\n",
      "True:      [0, 0, 0, 0, 1, 8, 8, 0, 1, 8, 0, 0, 1, 8, 0, 0, 2, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 180\n",
      "Predicted: [0 0 1 2 2 0]\n",
      "True:      [0, 0, 1, 2, 0, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 216\n",
      "Predicted: [0 0 0 0 1 2 0 3 4 0 0 4 4 4 0 4 0 0]\n",
      "True:      [0, 0, 0, 0, 1, 2, 3, 3, 4, 0, 0, 4, 4, 4, 0, 4, 0, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 218\n",
      "Predicted: [0 0 1 2 1 0 0 0 4 0 4]\n",
      "True:      [0, 0, 1, 2, 0, 0, 0, 0, 4, 0, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 228\n",
      "Predicted: [0 0 0 1 3 3 0 0 5 4]\n",
      "True:      [0, 0, 0, 1, 0, 3, 0, 0, 5, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 230\n",
      "Predicted: [0 0 0 0 0 1 2 3 3 0 0 4 4 0 0 4 0 1 4 0 4 4 0 1 2 8]\n",
      "True:      [0, 0, 0, 0, 0, 1, 2, 3, 3, 0, 0, 4, 4, 0, 0, 4, 0, 5, 5, 5, 4, 4, 0, 1, 2, 8]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 231\n",
      "Predicted: [0 0 1 2 0 0 4 4 0 4 0 0 0 5 4]\n",
      "True:      [0, 0, 1, 2, 0, 0, 4, 4, 0, 0, 0, 0, 0, 5, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 242\n",
      "Predicted: [0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 4 0 0 0 0 4 0 4 0]\n",
      "True:      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 301\n",
      "Predicted: [0 0 0 1 2 0 0 0 0 0 0 4 0 0 0 3 3 3 0 0 6 0 0 0 0 0]\n",
      "True:      [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 3, 3, 0, 0, 0, 6, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 309\n",
      "Predicted: [0 0 0 1 2 0 0 4 4 0 4]\n",
      "True:      [0, 0, 0, 1, 2, 0, 0, 0, 4, 0, 4]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 321\n",
      "Predicted: [0 0 1 4 0 4 0 0 0 7 7]\n",
      "True:      [0, 0, 1, 4, 0, 4, 0, 0, 0, 0, 0]\n",
      "--------------------------------------------\n",
      "Index with mismatch: 781\n",
      "Predicted: [0 0 0 0 1 2 0 0 4 0 4 0 0 0 0 0 0 0 0 4]\n",
      "True:      [0, 0, 0, 0, 1, 2, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 6]\n",
      "--------------------------------------------\n",
      "Accuracy on dev_data: 0.9858\n",
      "Sequences with only last index error: 1\n"
     ]
    }
   ],
   "source": [
    "# Predict on the development set\n",
    "preds_dev = model.predict([X_d,X_categories_d])\n",
    "preds_dev = np.argmax(preds_dev, axis=-1)\n",
    "\n",
    "count = 0  # Count of completely correct sequences\n",
    "last_index_error_count = 0  # Count of sequences with only last index error\n",
    "\n",
    "for i in range(len(dev_data)):\n",
    "    # Get original sequence lengths before padding\n",
    "    original_length = len(dev_data[i])\n",
    "    \n",
    "    # Extract predictions and true dev_labels for the original sequence\n",
    "    pred_seq = preds_dev[i][:original_length]\n",
    "    true_seq = dev_labels[i]  # Original dev_labels are unpadded\n",
    "    \n",
    "    # Check if the sequence is entirely correct\n",
    "    if (pred_seq == true_seq).all():\n",
    "        count += 1\n",
    "    else:\n",
    "        # Check if only the last index is incorrect\n",
    "        if (pred_seq[:-1] == true_seq[:-1]).all() and (pred_seq[-1] != true_seq[-1]):\n",
    "            last_index_error_count += 1\n",
    "        \n",
    "        # Print debug information for mismatches\n",
    "        print(f\"Index with mismatch: {i}\")\n",
    "        \n",
    "        print(f\"Predicted: {pred_seq}\")\n",
    "        print(f\"True:      {true_seq}\")\n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy on dev_data: {count / len(dev_data):.4f}\")\n",
    "print(f\"Sequences with only last index error: {last_index_error_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
